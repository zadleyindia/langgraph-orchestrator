# LangGraph Orchestrator Environment Configuration
# Copy this file to .env and fill in your values

# LLM Configuration
OPENAI_API_KEY=your_openai_api_key_here
LLM_PROVIDER=openai  # Options: openai, anthropic, google
LLM_MODEL=gpt-4      # Model to use (provider-specific)
LLM_TEMPERATURE=0.1  # Temperature for responses (0.0-1.0)
LLM_MAX_TOKENS=4096  # Maximum tokens per response

# Alternative LLM Providers (optional)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_api_key_here

# Memory Configuration
ENABLE_MEMORY=true
MEMORY_MODE=simulated  # Options: simulated, mcp, supergateway

# MCP Memory Configuration (if using MCP mode)
MCP_MEMORY_URL=http://localhost:3003
MCP_MEMORY_TOKEN=your_memory_token_here

# Agent Configuration
MAX_REACT_STEPS=7
REACT_TEMPERATURE=0.3
ENABLE_REACT=true

# Interface Configuration
API_PORT=8000
ENABLE_WEBSOCKET=true
ENABLE_VOICE=false

# Logging
LOG_LEVEL=INFO